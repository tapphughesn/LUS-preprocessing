{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example demonstrates how to use kwcoco to write a very simple torch\n",
    "dataset. This assumes the dataset will be single-image RGB inputs.\n",
    "\n",
    "This example aims for clairity over being concise. There are APIs exposed by\n",
    "kwcoco (and its sister module ndsampler) that can perform the same tasks more\n",
    "efficiently and with fewer lines of code.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KWIMAGE_DISABLE_C_EXTENSIONS\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import kwcoco\n",
    "import kwimage\n",
    "import kwarray\n",
    "import numpy as np\n",
    "import ubelt as ub\n",
    "\n",
    "\n",
    "class KWCocoSimpleTorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple torch dataloader where each image is considered a single item.\n",
    "\n",
    "    Args:\n",
    "        coco_dset (kwcoco.CocoDataset | str):\n",
    "            something coercable to a kwcoco dataset, this could either be a\n",
    "            :class:`kwcoco.CocoDataset` object, a path to a kwcoco manifest on\n",
    "            disk, or a special toydata code. See\n",
    "            :func:`kwcoco.CocoDataset.coerce` for more details.\n",
    "\n",
    "\n",
    "        input_dims (Tuple[int, int]): These are the (height, width) dimensions\n",
    "            that the image will be resized to.\n",
    "\n",
    "        antialias (bool, default=False): If true, we will antialias before\n",
    "            downsampling.\n",
    "\n",
    "        rng (RandomState | int | None): an existing random number generator or\n",
    "            a random seed to produce deterministic augmentations.\n",
    "\n",
    "    Example:\n",
    "        >>> # xdoctest: +REQUIRES(module:torch)\n",
    "        >>> from kwcoco.examples.simple_kwcoco_torch_dataset import *  # NOQA\n",
    "        >>> import kwcoco\n",
    "        >>> coco_dset = kwcoco.CocoDataset.demo('shapes8')\n",
    "        >>> input_dims = (384, 384)\n",
    "        >>> self = torch_dset = KWCocoSimpleTorchDataset(coco_dset, input_dims=input_dims)\n",
    "        >>> index = len(self) // 2\n",
    "        >>> item = self[index]\n",
    "        >>> # xdoctest: +REQUIRES(--show)\n",
    "        >>> import kwplot\n",
    "        >>> kwplot.figure(doclf=True, fnum=1)\n",
    "        >>> kwplot.autompl()\n",
    "        >>> canvas = item['inputs']['rgb'].numpy().transpose(1, 2, 0)\n",
    "        >>> # Construct kwimage objects for batch item visualization\n",
    "        >>> dets = kwimage.Detections(\n",
    "        >>>     boxes=kwimage.Boxes(item['labels']['cxywh'], 'cxywh'),\n",
    "        >>>     class_idxs=item['labels']['class_idxs'],\n",
    "        >>>     classes=self.classes,\n",
    "        >>> ).numpy()\n",
    "        >>> # Overlay annotations on the image\n",
    "        >>> canvas = dets.draw_on(canvas)\n",
    "        >>> kwplot.imshow(canvas)\n",
    "        >>> kwplot.show_if_requested()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, coco_dset, input_dims=None, antialias=False, rng=None):\n",
    "\n",
    "        # Store a pointer to the coco dataset\n",
    "        self.coco_dset = kwcoco.CocoDataset.coerce(coco_dset)\n",
    "\n",
    "        if input_dims is None:\n",
    "            raise ValueError(ub.paragraph(\n",
    "                '''\n",
    "                Must currently specify the height/width input dimensions to the\n",
    "                network, so we can resample to that expected shape.\n",
    "                '''))\n",
    "\n",
    "        self.input_dims = input_dims\n",
    "        self.antialias = antialias\n",
    "\n",
    "        self.rng = kwarray.ensure_rng(rng)\n",
    "\n",
    "        # Build a \"grid\" that maps an index to enough information to sample\n",
    "        # data used to construct a batch item. In this case each sample\n",
    "        # returned by __getitem__ will correspond to an entire image, so we\n",
    "        # just store a list of image-ids. Note, if we are only interested in\n",
    "        # some subset images, we could perform a filtering step here.\n",
    "        self.gids = list(self.coco_dset.imgs.keys())\n",
    "\n",
    "        # This is a kwcoco.CategoryTree object and it helps maintain the\n",
    "        # mappings between contiguous class indexes (used by the network)\n",
    "        # integer class ids (used by the kwcoco file) and string class names\n",
    "        # (used by humans). Be sure that any torch network you build holds a\n",
    "        # copy of this object (see self.classes.__json__), so the class\n",
    "        # encoding is always coupled with the model.\n",
    "        self.classes = self.coco_dset.object_categories()\n",
    "\n",
    "        self.augment = True\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of items in the Dataset\n",
    "        \"\"\"\n",
    "        return len(self.gids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Construct a batch item to be used in training\n",
    "        \"\"\"\n",
    "        gid = self.gids[index]\n",
    "\n",
    "        if 0:\n",
    "            # Note: there is an experimental method for lazy image operations\n",
    "            # we may default to recommending in the future.\n",
    "            raw_img = self.coco_dset.delayed_load(gid).finalize()\n",
    "        else:\n",
    "            # For now, we will just do things in the most transparent way\n",
    "            image_fpath = self.coco_dset.get_image_fpath(gid)\n",
    "            # Note: might need to use itk imread (or better extend\n",
    "            # kwimage.imread to also wrap itk formats)\n",
    "            raw_img = kwimage.imread(image_fpath)\n",
    "\n",
    "        # Lookup the annotations that correspond to this image\n",
    "        aids = self.coco_dset.gid_to_aids[gid]\n",
    "\n",
    "        # The the specific dataset, model, and loss function is what defines\n",
    "        # what sort of label information is needed. Because that is not defined\n",
    "        # for this tutorial, we will show how to manipulate all the annotation\n",
    "        # information, but our final label will only consist of truth bounding\n",
    "        # boxes and category ids.\n",
    "        anns = [self.coco_dset.anns[aid] for aid in aids]\n",
    "\n",
    "        # kwimage data structures makes handling spatial annotations on\n",
    "        # images easier by bundling transformations of all annotations.\n",
    "        raw_dets = kwimage.Detections.from_coco_annots(anns, dset=self.coco_dset)\n",
    "\n",
    "        # Process the data and the annotations\n",
    "\n",
    "        # Use if you want to ensure grayscale images are interpreted as rgb\n",
    "        imdata = raw_img\n",
    "        dets = raw_dets\n",
    "\n",
    "        # TODO: Do whatever sort of augmentation you want here.\n",
    "        # Remember, whenever we transform the image, we also need to transform\n",
    "        # the annotations.\n",
    "        if self.augment:\n",
    "            # Build up an Affine augmentation\n",
    "\n",
    "            aug_transform = kwimage.Affine.eye()\n",
    "            if self.rng.rand() < 0.5:\n",
    "                # horizontal flip with 0.5 probability\n",
    "                h, w = imdata.shape[0:2]\n",
    "                aug_transform = kwimage.Affine.affine(\n",
    "                    scale=(-1, 1), about=(w / 2, h / 2)) @ aug_transform\n",
    "\n",
    "            if 0 and self.rng.rand() < 0.8:\n",
    "                # small translation / scale perterbation with 80% probability\n",
    "                aug_transform = kwimage.Affine.random(\n",
    "                    # scale= not implemented as a distribution yet\n",
    "                    # offset= not implemented as a distribution yet\n",
    "                    shear=0,\n",
    "                    theta=0,\n",
    "                    rng=self.rng) @ aug_transform\n",
    "\n",
    "            # Augment the image and the dets\n",
    "            imdata = np.ascontiguousarray(imdata)\n",
    "            \n",
    "            print(imdata.dtype)\n",
    "            print(imdata.flags)\n",
    "            print(aug_transform)\n",
    "            \n",
    "            imdata = kwimage.warp_affine(imdata, aug_transform.__array__())\n",
    "            dets = dets.warp(aug_transform.__array__())\n",
    "\n",
    "        # Use the convention where dims/shape are ordered as height,width and\n",
    "        # size/dsize are width,height.\n",
    "        input_dsize = self.input_dims[::-1]\n",
    "\n",
    "        # Use imresize to finalize\n",
    "        imdata, info = kwimage.imresize(imdata, dsize=input_dsize,\n",
    "                                        antialias=self.antialias,\n",
    "                                        return_info=True)\n",
    "\n",
    "        resize_tf = kwimage.Affine.affine(offset=info['offset'],\n",
    "                                          scale=info['scale'])\n",
    "        dets = dets.warp(resize_tf.__array__())\n",
    "\n",
    "        if 0:\n",
    "            # The `dets.data` and `dets.meta` dictionaries contain annot info\n",
    "            dets.data['boxes']\n",
    "            dets.data['segmentations']\n",
    "            dets.data['keypoints']\n",
    "            dets.data['class_idxs']\n",
    "\n",
    "        cxywh = torch.from_numpy(dets.data['boxes'].to_cxywh().data)\n",
    "        class_idxs = torch.from_numpy(dets.data['class_idxs'])\n",
    "        rgb_chw = torch.from_numpy(imdata.transpose(2, 0, 1)).float() / 255.\n",
    "\n",
    "        # It is best practices that a data loader returns a dictionary\n",
    "        # so it is easy to add / remove data input and llabel information.\n",
    "        item = {\n",
    "            # Encode the inputs to the network for torch\n",
    "            'inputs': {\n",
    "                'rgb': rgb_chw,\n",
    "            },\n",
    "\n",
    "            # Encode the truth labels for torch\n",
    "            'labels': {\n",
    "                'cxywh': cxywh,\n",
    "                'class_idxs': class_idxs,\n",
    "            }\n",
    "        }\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kw = {\n",
      "    'n_imgs': 8,\n",
      "    'rng': 8,\n",
      "}\n",
      "[cacher] tryload fname=toy_dset_stamp_v016\n",
      "[cacher] ... toy_dset_stamp_v016 cache hit\n",
      "read dset_fpath = '/home/nick/.cache/kwcoco/demodata_bundles/shapes_8_tphzxqtzakcghy/data.kwcoco.json'\n",
      "uint8\n",
      "  C_CONTIGUOUS : True\n",
      "  F_CONTIGUOUS : False\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "  UPDATEIFCOPY : False\n",
      "\n",
      "<Affine(array([[ -1.,   0., 600.],\n",
      "       [  0.,   1.,   0.],\n",
      "       [  0.,   0.,   1.]]))>\n"
     ]
    }
   ],
   "source": [
    "# xdoctest: +REQUIRES(module:torch)\n",
    "import kwcoco\n",
    "coco_dset = kwcoco.CocoDataset.demo('shapes8')\n",
    "input_dims = (384, 384)\n",
    "self = torch_dset = KWCocoSimpleTorchDataset(coco_dset, input_dims=input_dims)\n",
    "index = len(self) // 2\n",
    "item = self[index]\n",
    "# xdoctest: +REQUIRES(--show)\n",
    "import kwplot\n",
    "kwplot.figure(doclf=True, fnum=1)\n",
    "kwplot.autompl()\n",
    "canvas = item['inputs']['rgb'].numpy().transpose(1, 2, 0)\n",
    "# Construct kwimage objects for batch item visualization\n",
    "dets = kwimage.Detections(\n",
    "    boxes=kwimage.Boxes(item['labels']['cxywh'], 'cxywh'),\n",
    "    class_idxs=item['labels']['class_idxs'],\n",
    "    classes=self.classes,\n",
    ").numpy()\n",
    "# Overlay annotations on the image\n",
    "canvas = dets.draw_on(canvas)\n",
    "kwplot.imshow(canvas)\n",
    "kwplot.show_if_requested()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kwplot\n",
      "  Downloading kwplot-0.4.8-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: ubelt in /home/nick/anaconda3/lib/python3.7/site-packages (from kwplot) (0.9.5)\n",
      "Requirement already satisfied: six in /home/nick/anaconda3/lib/python3.7/site-packages (from kwplot) (1.15.0)\n",
      "Requirement already satisfied: kwarray in /home/nick/anaconda3/lib/python3.7/site-packages (from kwplot) (0.5.19)\n",
      "Requirement already satisfied: matplotlib in /home/nick/anaconda3/lib/python3.7/site-packages (from kwplot) (3.2.2)\n",
      "Requirement already satisfied: kwimage in /home/nick/anaconda3/lib/python3.7/site-packages (from kwplot) (0.7.8)\n",
      "Requirement already satisfied: scipy in /home/nick/anaconda3/lib/python3.7/site-packages (from kwarray->kwplot) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/nick/anaconda3/lib/python3.7/site-packages (from kwarray->kwplot) (1.19.5)\n",
      "Requirement already satisfied: shapely in /home/nick/anaconda3/lib/python3.7/site-packages (from kwimage->kwplot) (1.7.1)\n",
      "Requirement already satisfied: Pillow in /home/nick/anaconda3/lib/python3.7/site-packages (from kwimage->kwplot) (7.2.0)\n",
      "Requirement already satisfied: scikit-image in /home/nick/anaconda3/lib/python3.7/site-packages (from kwimage->kwplot) (0.15.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/nick/anaconda3/lib/python3.7/site-packages (from matplotlib->kwplot) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nick/anaconda3/lib/python3.7/site-packages (from matplotlib->kwplot) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/nick/anaconda3/lib/python3.7/site-packages (from matplotlib->kwplot) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nick/anaconda3/lib/python3.7/site-packages (from matplotlib->kwplot) (0.10.0)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /home/nick/anaconda3/lib/python3.7/site-packages (from scikit-image->kwimage->kwplot) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/nick/anaconda3/lib/python3.7/site-packages (from scikit-image->kwimage->kwplot) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/nick/anaconda3/lib/python3.7/site-packages (from scikit-image->kwimage->kwplot) (2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/nick/anaconda3/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->kwimage->kwplot) (4.4.2)\n",
      "Requirement already satisfied: ordered-set in /home/nick/anaconda3/lib/python3.7/site-packages (from ubelt->kwplot) (4.0.2)\n",
      "Installing collected packages: kwplot\n",
      "Successfully installed kwplot-0.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install kwplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = kwimage.Affine.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([1.80318291]), array([-0.04315878]), array([0.4476843]),\n",
       "       array([0.07705842]), array([1.00992441]), array([0.08057904]), 0,\n",
       "       0, 1], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aff.matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Affine(array([[-1., -0.,  0.],\n",
       "       [-0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]]))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwimage.Affine.affine(scale=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
